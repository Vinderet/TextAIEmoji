import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox, filedialog
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, GlobalMaxPooling1D
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Глобальные переменные
data_path = ""  # Путь к файлу данных
model_lstm = None
model_cnn = None
tokenizer = None
le = None

# Загрузка данных (замените это на ваш загрузочный код)
# df = pd.read_csv("ваш_файл.csv")

# ...

# Создание GUI
def train_model():
    global data_path, model_lstm, model_cnn, tokenizer, le

    if not data_path:
        messagebox.showerror("Ошибка", "Укажите путь к файлу данных в настройках.")
        return

    # Загрузка данных
    df = pd.read_csv(data_path)

    # Предварительная обработка текста
    df['text'] = df['text'].apply(preprocess_text)

    # Разделение данных на обучающую и тестовую выборку
    X_train, X_test, y_train, y_test = train_test_split(df['text'], df['emotion'], test_size=0.2, random_state=42)

    # Преобразование меток в числовой формат
    le = LabelEncoder()
    y_train_encoded = le.fit_transform(y_train)
    y_test_encoded = le.transform(y_test)

    # Токенизация текста
    max_words = 10000  # Максимальное количество слов для токенизации
    tokenizer = Tokenizer(num_words=max_words)
    tokenizer.fit_on_texts(X_train)

    # Преобразование текста в числовой формат
    X_train_seq = tokenizer.texts_to_sequences(X_train)
    X_test_seq = tokenizer.texts_to_sequences(X_test)

    # Построение последовательности одинаковой длины
    max_len = 100  # Максимальная длина последовательности
    X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')
    X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')

    # Построение LSTM модели
    model_lstm = Sequential()
    model_lstm.add(Embedding(max_words, 128, input_length=max_len))
    model_lstm.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))
    model_lstm.add(Dense(7, activation='softmax'))

    # Компиляция модели
    model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    # Обучение модели
    model_lstm.fit(X_train_pad, y_train_encoded, epochs=5, batch_size=64, validation_split=0.1)

    # Построение CNN модели
    model_cnn = Sequential()
    model_cnn.add(Embedding(max_words, 128, input_length=max_len))
    model_cnn.add(Conv1D(128, 5, activation='relu'))
    model_cnn.add(GlobalMaxPooling1D())
    model_cnn.add(Dense(7, activation='softmax'))

    # Компиляция модели
    model_cnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    # Обучение модели
    model_cnn.fit(X_train_pad, y_train_encoded, epochs=5, batch_size=64, validation_split=0.1)

    messagebox.showinfo("Обучение", "Модели успешно обучены.")

# Остальной код для GUI остается без изменений
# ...

# Запуск основного цикла
root.mainloop()
